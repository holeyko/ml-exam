# Многослойная «нейронная» сеть

**Искусственная нейронная сеть (ANN)**:

- Искусственная нейронная сеть – это модель, вдохновлённая работой человеческого мозга, которая используется для решения задач машинного обучения, таких как классификация и регрессия.
- Она состоит из множества простых элементов – нейронов, соединённых между собой.

## Нейрон

- Нейрон – это основная единица нейронной сети.
- Каждый нейрон получает входные данные, обрабатывает их и выдаёт выходное значение.
- Нейрон может быть представлен как математическая функция: он принимает несколько входов, умножает их на веса, складывает результаты и применяет функцию активации, чтобы получить выход.

### Пример нейрона

- Входные данные: $x_1,x_2, \ldots ,x_n$
- Веса: $w_1,w_2, \ldots ,w_n$
- Сумма взвешенных входов: $z=w_1x_1+w_2x_2+ \ldots +w_nx_n+b$ (где $b$ – смещение, или bias)
- Функция активации: a=σ(z)a=σ(z), где σσ – функция активации (например, сигмоида, ReLU и т.д.)

### Слой нейронов

- Нейроны обычно организуются в слои.
- Каждый слой состоит из нескольких нейронов, которые одновременно обрабатывают входные данные.

### Многослойная нейронная сеть (MLP)

- Многослойная нейронная сеть состоит из нескольких слоёв нейронов.
- Обычно имеет три типа слоёв:
  - **Входной слой**: принимает входные данные.
  - **Скрытые слои**: один или несколько слоёв, которые обрабатывают данные, извлекая признаки.
  - **Выходной слой**: выдаёт конечное предсказание.

#### Подробное объяснение слоёв

**Типы слоёв**:

- **Входной слой**:
  - Принимает исходные данные. Например, в задаче классификации изображений входными данными могут быть пиксели изображения.
  - Каждый нейрон во входном слое представляет один признак входных данных.
- **Скрытые слои**:
  - Обрабатывают данные, извлекая признаки и паттерны.
  - Могут быть один или несколько скрытых слоёв, в зависимости от сложности задачи.
  - Нейроны в скрытых слоях могут быть соединены различными способами:
    - **Полносвязные слои (Fully Connected Layers)**: каждый нейрон соединён с каждым нейроном из предыдущего и следующего слоя.
    - **Свёрточные слои (Convolutional Layers)**: каждый нейрон соединён с небольшой областью предыдущего слоя.
    - **Рекуррентные слои (Recurrent Layers)**: нейроны могут иметь связи с самим собой или с нейронами из предыдущих временных шагов.
- **Выходной слой**:
  - Выдаёт результат модели.
  - В зависимости от задачи выходные данные могут быть:
    - В задаче классификации: вероятности классов (например, softmax для многоклассовой классификации).
    - В задаче регрессии: конкретное числовое значение (например, предсказанная цена дома).

### Функции активации

- Функции активации помогают моделировать нелинейности.
- Примеры функций активации:
  - **Сигмоида**: $\sigma(z)=\frac{1}{1 + e^{-z}}$
  - **ReLU (Rectified Linear Unit)**: $ReLU(z)=max⁡(0,z)$
  - **Tanh**: $\tanh(z)=\frac{e^z - e^{-z}}{e^z + e^{-z}}$

### Обучение нейронной сети

- Нейронная сеть обучается с помощью алгоритма обратного распространения ошибки (backpropagation).
- Цель обучения – минимизировать ошибку модели (разницу между предсказанными и истинными значениями) путём настройки весов и смещений.

#### Подробное объяснение обучения

**Шаги обучения**:

- **Шаг 1: Прямое распространение (forward propagation)**:
  - Входные данные проходят через все слои сети, чтобы получить предсказание.
  - Например, в задаче классификации изображений пиксели изображения проходят через входной слой, затем через скрытые слои, и, наконец, через выходной слой, который выдаёт вероятность каждого класса.
- **Шаг 2: Вычисление ошибки**:
  - Вычисляется ошибка модели, используя функцию потерь (например, среднеквадратическая ошибка для регрессии или кросс-энтропия для классификации).
- **Шаг 3: Обратное распространение (backpropagation)**:
  - Ошибка распространяется назад через сеть.
  - Используем метод градиентного спуска для корректировки весов и смещений.
  - В каждом слое вычисляем градиенты функции потерь по отношению к весам и корректируем веса, чтобы минимизировать ошибку.
