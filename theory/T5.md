# Окно Парзена-Розенблатта и формула Надарая-Ватсона

**Окно Парзена-Розенблатта** - это метод оценки плотности вероятности функции, использующий ядровые функции (например, гауссова функция) для сглаживания данных. По сути, окно Парзена-Розенблатта заменяет каждый отдельный образец распределения области плотности, где соседние образцы взвешиваются с учетом их близости. Чем ближе образец к точке оценки, тем больше его вес. Это сглаживание позволяет оценить общую форму распределения, даже если отдельные данные содержат шум или выбросы.

Используется для классификации в методе ближайших соседей. Фактически здесь и получаем два вида алгоритма метода ближайших соседей с использованием ядерной функции и Парзенского окна. С фиксированной шириной окна:

$$
  a(u, ~ \mathcal{D}_{\text{train}}, ~ h, ~ K) = \argmax_{y \in Y}{\sum_{i = 1}^{|\mathcal{D}_{\text{train}}|}{[y(x_{(u, i)}) = y] \cdot K\left(\dfrac{\rho(u, x_{(u, i)})}{h}\right)}}
$$

С нефиксированной шириной окна:

$$
  a(u, ~ \mathcal{D}_{\text{train}}, ~ k, ~ K) = \argmax_{y \in Y}{\sum_{i = 1}^{|\mathcal{D}_{\text{train}}|}{[y(x_{(u, i)}) = y] \cdot K\left(\dfrac{\rho(u, x_{(u, i)})}{\rho(u, x_{(u, k + 1)})}\right)}}
$$

Ключевая идея **формулы Надарая-Ватсона**: пусть функция $a_{\delta}(x, \mathcal{D}_{\text{train}}) = \delta$ линейна в некоторой области $u$ искомого объекта, также предположим, что эмпирический риск следующий:

$$
  \mathcal{L}(\delta) = \sum_{i = 1}^{|\mathcal{D}_{\text{train}}|}{w_{(i, u)} \cdot (\delta - y(x_i))^{2}},
$$

будем также взвешивать его, риск представляет собой взвешенную сумму квадратов. Если аналитически решить задачу минимизации $\mathcal{L}$ относительно $\delta$ то получится, что оптимальное решение — среднее взвешенное.

Сама формула:

$$
  a_{\text{NPR}}(u, \mathcal{D}_{\text{train}}) = \dfrac{\sum_{i = 1}^{|\mathcal{D}_{\text{train}}|}{y_{i}w_{(i, u)}}}{\sum_{i = 1}^{|\mathcal{D}_{\text{train}}|}{w_{(i, u)}}} = \dfrac{\sum_{x_{i} \in \mathcal{D}_{\text{train}}}{y_iK\left(\dfrac{\rho(x_i, u)}{h}\right)}}{\sum_{x_i \in \mathcal{D}_{\text{train}}}{K\left(\dfrac{\rho(x_i, u)}{h}\right)}}
$$

По сути, формула Надарая-Ватсона учитывает соседние данные при прогнозировании значений регрессии, при этом более близкие данные имеют больший вес. Это позволяет строить гладкие линии регрессии, даже если данные содержат шум или выбросы.
