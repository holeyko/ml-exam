# Автоматическое дифференцирование

**Виды автоматического дифференцирование**:

- **Прямое автоматическое дифференцирование (Forward Mode)**: производная вычисляется одновременно с самой функцией, эффективен для функций с **малым числом входов** и **большим числом выходов**
- **Обратное автоматическое дифференцирование (Reverse Mode)**: производная вычисляется с использованием обратного распространения через вычислительный граф функции, эффективен для функций с **большим числом входов** и **малым числом выходов** (как в нейронных сетях)

**Почему используем автоматическое дифференцирование?**
Рассмотрим другие способы:

- **Численное дифференцирование**:

  $$f'(x) = \frac{f(x + h) - f(x)}{h}$$

  Проблемы: погрешность из-за выбора h, медленное выполнение

- **Символьное дифференцирование**:

  $$f(x) = x^2 \to f'(x) = 2x$$

  Проблемы: может привести к сложным и громоздким выражениям
- **Автоматическое дифференцирование**: использует правила дифференцирование на уровне вычислительного графа и основано на цепочном правиле дифференцирования.

  Например, если мы знаем, что в некоторой точке $x_0$ значение некоторой функции $f(x_0) = f_0$, а $f'(x_0) = f'_0$, тогда для функции $h(x) = f^2(x)$ мы можем найти и её значение и производную в точке $x_0: h(x_0) = f^2_0; h'(x) = 2f_0f'_0$. Это и есть цепочное правило дифференцирования.
