# Метод Xavier. Метод He

## Основы

1. **Нейронные сети**:
    - Нейронные сети состоят из множества нейронов, соединённых между собой.
    - Каждый нейрон имеет веса, которые умножаются на входные данные, и смещение (bias).
2. **Инициализация весов**:
    - Перед началом обучения нейронной сети необходимо задать начальные значения весов.
    - Инициализация весов важна, так как она влияет на то, как быстро и насколько хорошо будет обучаться сеть.

## Проблема

**Проблема инициализации**:

- Если начальные веса слишком малы, сигналы, проходящие через сеть, могут стать очень слабыми, и обучение будет медленным.
- Если начальные веса слишком велики, сигналы могут стать слишком сильными, что приведёт к нестабильному обучению.
- Поэтому важно правильно выбрать начальные значения весов.

## Метод Xavier (или Glorot)

- Метод Xavier был предложен Xavier Glorot и Yoshua Bengio в 2010 году.
- Этот метод предназначен для улучшения инициализации весов в нейронных сетях с сигмоидальными (sigmoid) или гиперболическими тангенциальными функциями активации (tanh).

### Как работает метод Xavier

**Основная идея метода Xavier**:

- Цель – сохранить дисперсию активаций одинаковой на всех слоях сети.
- Начальные веса выбираются так, чтобы сигналы, проходящие через нейроны, не затухали и не усиливались слишком сильно.
**Формула метода Xavier**:
- Веса инициализируются случайным образом из равномерного распределения:

  $$
  W \sim \mathcal{U}\left(-\frac{\sqrt{6}}{\sqrt{n_{\text {in }}+n_{\text {out }}}}, \frac{\sqrt{6}}{\sqrt{n_{\text {in }}+n_{\text {out }}}}\right)
  $$

- Здесь $n_{in}$​ – количество входов в нейрон, $n_{out}​$ – количество выходов из нейрона.

## Метод He (или He-et-al)

- Метод He был предложен Kaiming He и его коллегами в 2015 году.
- Этот метод предназначен для улучшения инициализации весов в нейронных сетях с функцией активации ReLU (Rectified Linear Unit).

### Как работает метод He

**Основная идея метода He**:

- Цель – сохранить дисперсию активаций одинаковой на всех слоях сети, учитывая, что ReLU обнуляет часть выходов.
- Начальные веса выбираются так, чтобы сигналы не затухали и не усиливались слишком сильно, особенно с учётом особенности ReLU.
**Формула метода He**:
- Веса инициализируются случайным образом из нормального распределения:

  $$
  W \sim \mathcal{N}\left(0,\frac{2}{n_{in}}\right)
  $$

  Здесь $n_{in}$​ – количество входов в нейрон.

## Различие между методами Xavier и He

- **Целевая функция активации**:
  - Метод Xavier лучше подходит для сигмоидальных и тангенциальных функций активации.
  - Метод He лучше подходит для функций активации ReLU и её вариаций.
- **Формула**:
  - В методе Xavier веса инициализируются из равномерного распределения с диапазоном, зависящим от количества входов и выходов.
  - В методе He веса инициализируются из нормального распределения с дисперсией, зависящей от количества входов.
