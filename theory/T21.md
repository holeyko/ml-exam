# Многослойная «нейронная» сеть

**Структура MLP**:

- **Входной слой** содержит нейроны, которые принимают входные данные, количество нейронов соответствует числу признаков во входных данных
- **Скрытые слои** - это один или несколько слоев нейронов, которые обрабатывают входные данные, каждый нейрон в скрытом слое получает на вход **выходы всех нейронов из предыдущего слоя**
- **Выходной слой** содержит нейроны, которые выдают результат работы сети, количество нейронов соответствует числу классов в задаче классификации или одному нейрону в. задаче регрессии

MLP обучается с использованием алгоритма обратного распространения ошибки (backpropagation), состоящего из следующих шагов:

- **Прямое распространение (forward pass)**: входные данные проходят через все соли сети
- **Вычисление ошибки**: на выходном слое вычисляется ошибки (например, с использованием кросс-энтропии для классификации или среднеквадратичной ошибки для регрессии)
- **Обратное распространение (backpropagation)**: ошибка распространяется назад через все слои сети, градиенты шибки вычисляются для каждого веса с использованием **правила цепочки (chain rule)**
- **Обновление весов**: веса обновляются с использованием алгоритма градиентного спуска или его модификаций, например, Adam
