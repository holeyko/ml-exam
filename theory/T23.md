# Метод Xavier. Метод He

## Методы инициализации весов Xavier и He

### Зачем нужно инициализировать веса?

В начале обучения нейронной сети веса задаются случайным образом. Если выбрать их неправильно, сеть может плохо обучаться. Правильная инициализация весов помогает нейронной сети быстрее и лучше находить оптимальные значения весов.

### Проблемы с плохой инициализацией весов

1. **Затухающие градиенты (vanishing gradients)**:
 Если начальные веса слишком малы, сигналы и градиенты становятся очень маленькими, когда проходят через слои сети. В результате, изменения весов становятся настолько малыми, что обучение практически останавливается.
1. **Взрывающиеся градиенты (exploding gradients)**:
    Если начальные веса слишком велики, сигналы и градиенты становятся очень большими. Веса изменяются слишком сильно, что делает обучение нестабильным.

### Метод Xavier

Помогает избежать затухающих и взрывающихся градиентов, правильно выбирая начальные веса.

#### Как работает метод Xavier?

Метод Xavier выбирает веса так, чтобы сигналы (активации) и градиенты имели одинаковую дисперсию (вариативность) на всех слоях сети.

### Метод He

Делает то же самое, но особенно хорошо работает с функцией активации ReLU

#### Как работает He?

Метод He выбирает веса так, чтобы сигналы и градиенты имели одинаковую дисперсия на всех слоях сети, учитывая особенности ReLU. ReLU пропускает только положительные значения и обнуляет отрицательные. Метод He учитывает это и инициализирует веса немного иначе.

#### Почему He лучше подходит для ReLU?

Когда используем ReLU, половина нейронов на каждом слое обычно "умирает" (их выход равен 0). Метод He учитывает это и задает веса так, чтобы оставшаяся половина нейронов давала подходящие значения для продолжения обучения. Это помогает избежать затухающих градиентов, что часто происходит при использовании ReLU с другими методами инициализации.
