# Метод AdaBoost

Данный алгоритм применетелен для бинарной классификации $Y = \{-1, +1\}, для аппроксимации порогового функционала качества был предложен использовать такую экспоненциальную функцию потерь, где $M$ - это отступ:

$$
  Q_{T} = \sum_{i = 1}^{n}{\left([M_{i} < 0]\right)} \leqslant \sum_{i = 1}^{n}{\left(\exp{(-M_{i})}\right)} = \hat{Q}_{T}
$$

Для поиска весового коэффициента $\alpha_{t}$ и алгоритма $b_{t}$ на шаге $t$ мы получаем следующее:

$$
  Q_{T} \leqslant \hat{Q}_{T} = \sum_{i = 1}^{n}{\left(\exp{\left(-y_{i} \cdot \sum_{t = 1}^{T - 1}{\left(\alpha_{t}b_{t}(x_{i})\right)}\right)} \cdot \exp{\left(-y_{i} \cdot \alpha_{T} \cdot b_{T}(x_{i})\right)}\right)}
$$

Все предыдущие весовые коэффициенты и алгоритмы мы фиксируем (как в идеи бустинга), коли так - сумма $\sum_{t = 1}^{T - 1}{\left(\alpha_{t}b_{t}(x_{i})\right)}$ умноженная на метку класса $-y_{i}$ представляет из себя как некое число $\omega_{i}$ - это веса объектов в обучающей выборке, он будет *возрастать для плохо классифицируемых объектов* в текущей выборке.

При поиске текущего алгоритма $b_{T}(x_{i})$ при обучении (в большей степени) мы будем учитывать плохо классифицируемые образы $\omega_{i}$ и настраиваться под них - это и есть реализация принципа *бустинга* - последовательно обучать алгоритмы на объектах, на которых предыдущая композиция показала худшие результаты.

Нормируем веса: $\hat{\omega}_{i} = \dfrac{\omega_{i}}{\sum_{j = 1}^{n}{\omega_{j}}}$, где $i = 1, \ldots, n$ и используемых их для поиска *доли неверных классификаций* и *доли верных классификаций*:

$$
  \begin{aligned}
    N(b) &= \sum_{i = 1}^{n}{\left(\hat{\omega}_{i} \cdot [b(x_i) \neq y_i]\right)} \\
    P(b) &= \sum_{i = 1}^{n}{\left(\hat{\omega}_{i} \cdot [b(x_i) = y_i]\right)} = 1 - N(b)
  \end{aligned}
$$

Лучший алгоритм вычисляется как:

$$
  b_{t} = \argmin_{b \in \mathcal{B}}{(N(b))}
$$

Оптимальные весовые коэффициенты $\alpha_{T}$ вычисляются как:

$$
  \alpha_{T} = \dfrac{1}{2} \cdot \ln{\left(\dfrac{1 - N(b_{T})}{N(b_{T}) + 10^{-5}}\right)}
$$

Обобщённый алгоритм:

1. У нас есть набор данных $\mathcal{D}$ и количество алгоритмов $T$.
2. Для начала для каждого объекта мы устанавливаем в $\dfrac{1}{|\mathcal{D}|}$ - одинаковые веса.
3. Далее $T$ раз мы повторяем цикл.
   1. Найти наилучший текущий алгоритм по описанному выше правилу - находим ошибку при всей выборке с текущими весами.
   2. Для данного алгоритма мы найдем оптимальный коэффициент $\alpha_{T}$.
   3. Обновим веса объектов: $\omega_{i} = \omega_{i} \cdot \exp{\left(-\alpha_{t} \cdot y_{i} \cdot b_{t}(x_i)\right)}$, где всех $i = 1, \ldots, n$.
   4. Наконец, нормируем веса объектов.
