# Нейрон. Перцептрон

**Нейрон** - это базовый элемент искусственной нейронной сети. Нейрон принимает на вход несколько сигналов и выдаёт один выходной сигнал. Основная структура нейрона:
	- **Входы (Inputs)** $x_1, x_2,...,x_n$ - это входные сигналы;
	- **Веса (weights)** $w_1,w_2,...,w_n$ - это параметры, которые умножаются на входные сигналы, определяют важность каждого отдельного сигнала;
	- **Сумматор (weighted sum)** вычисляет взвешенную сумму входных сигналов: $z = w_1x_1 + w_2x_2 + ... + w_nx_n$ ;
	- **Активатор (activation function)** преобразует взвешенную сумму в выходной сигнал (пример - ReLU)
- **Перцептрон** - это один из самых простых типов искусственных нейронов и основная составляющая однослойной нейронной сети. Был предложен Фрэнком Розенблаттом в 1957 году (прошу прощения за историческую справку)

Перцептрон хорошо работает с линейными задачами, но имеет ограничения:
- **Линейная разделимость**: перцептрон может классифицировать данные только если они линейно разделимы. Это означает, что можно провести прямую (в случае двух измерений) или гиперплоскость, которая разделяет классы.
- **Нелинейные задачи**: перцептрон не может решат нелинейные задачи, такие как XOR-проблемы, где данные нельзя разделить одной прямой линией. XOR-проблема - четыре точки на плоскости с координатами и соответствующими значениями XOR: (0,0) = 0, (1,0) = 1, (0,1) = 1, (1,1) = 0. Между такими четыремя точками невозмоно провести прямую, разделяющую точки по класса 1 и 0.

Для решения нелинейных задач используют **многослойные перцептроны (MLP)**. Они состоят из нескольких слоев нейронов:
- **Входной слой**: принимает входные сигналы;
- **Скрытые слои**: обрабатывают входные сигналы, позволяют модели решать нелинейные задачи;
- **Выходной слой**: выдаёт конечный результат
