# Машинное обучение

Подготовительные билеты к экзамену по лекционным материалам курса **Машинное обучение** (6 семестр).

## Структура проекта

В репозитории разделение между *лекциями*, *теоретическим минимумом* и *экзаменом* по каталогам:

* [`lectures`](lectures/) - здесь хранится конспект лекционного материала;
* [`theory`](theory/) - здесь хранится материал к теоретическому минимуму;
* [`exam`](exam/) - здесь хранится материал к экзамену.

## Материал

Все билеты и конспекты написаны в формате [Markdown](https://en.wikipedia.org/wiki/Markdown), которые можно скомпилировать в PDF формат с помощью [`pandoc`](https://github.com/jgm/pandoc). Через двоеточие указан автор.

### Конспекты

* [Лекция №1. Гиперпараметры](lectures/L1-Hyperparameters.md)
* [Лекция №2. Непараметрические и метрические модели](lectures/L2-NonparametricModels.md)
* [Лекция №3. Линейные методы](lectures/L3-Linear.md)
* [Лекция №4. Метод опорных методов](lectures/L4-SVM.md)
* [Лекция №5. Байесовские методы](lectures/L5-Bayesian.md)
* [Лекция №6. Деревья решений и композиция алгоритмов](lectures/L6-DecisionTree.md)
* [Лекция №7. Автоматическое дифференцирование](lectures/L7-AutomaticDifferentiation.md)
* [Лекция №8. Глубокое обучение](lectures/L8-DeepLearning.md)
* [Лекция №9. Работа с изображениями и последовательностями](lectures/L9-ImagesAndSequences.md)
* [Лекция №10. Кластеризация](lectures/L10-Clustering.md)
* [Лекция №11. Выбор признаков](lectures/L11-FeatureSelection.md)
* [Лекция №12. Извлечение признаков](lectures/L12-FeatureExtraction.md)
* [Лекция №13. Генеративные методы](lectures/L13-Generative.md)

### Теоретический минимум

* [Гиперпараметры. Отличие от параметров.](theory/T1.md)
* [Поиск по сетке и случайный поиск.](theory/T2.md)
* [Расстояние Минковского и Махаланобиса.](theory/T3.md)
* [Ядерная функция для kNN и SVM.](theory/T4.md)
* [Окно Парзена-Розенблатта и формула Надарая-Ватсона.](theory/T5.md)
* [SMOTE, Tomek Links, LOWESS.](theory/T6.md)
* [Декорреляция.](theory/T7.md)
* [Метод линейной регрессии; гребневая регрессия; лассо Тибширани.](theory/T8.md)
* [Метод опорных векторов (общая идея).](theory/T9.md)
* [Метод логистической регрессии; сигмоида.](theory/T10.md)
* [Наивный байесовский классификатор](theory/T11.md)
* [Задача параметрической оценки плотности; принцип максимального правдоподобия.](theory/T12.md)
* [Дерево принятия решений; оценка разбиений.](theory/T13.md)
* [Бустрап; случайный лес; стэкинг.](theory/T14.md)
* [Бустинг алгоритмов; метод градиентного бустинга.](theory/T15.md)
* [Метод AdaBoost.](theory/T16.md)
* [Метод стохастического и пакетного градиентного спуска.](theory/T17.md)
* [Адаптивный и импульсный градиентный спуск.](theory/T18.md)
* [Автоматическое дифференцирование.](theory/T19.md)
* [SoftArgMax; SoftMax.](theory/T20.md)
* [Многослойная «нейронная» сеть.](theory/T21.md)
* [ResNet; ReLU.](theory/T22.md)
* [Метод Xavier; метод He.](theory/T23.md)
* [Дропаут; пакетная нормализация.](theory/T24.md)
* [Свёртка; паддинг; пулинг; страйд; тензор.](theory/T25.md)
* [Задача семантической сегментации; задача детекции объектов.](theory/T26.md)
* [Модуль памяти в рекуррентных сетях (LSTM).](theory/T27.md)
* [Механизм внимания в рекуррентных сетях (трансформер).](theory/T28.md)
* [Задача кластеризации; внешние меры оценки; внутренние меры оценки.](theory/T29.md)
* [Графовые методы кластеризации; иерархические методы кластеризации.](theory/T30.md)
* [Алгоритмы EM: k-means. c-means, GMM](theory/T31.md)
* [Алгоритм DBSCAN](theory/T32.md)
* [Уменьшение размерности; синтез признаков; выбор признаков; алгоритмы фильтрации.](theory/T33.md)
* [Алгоритмы-обертки; встроенные методы выбора признаков](theory/T34.md)
* [Алгоритм PCA](theory/T35.md)
* [Алгоритм t-SNE](theory/T36.md)
* [Автокодировщик](theory/T37.md)
* [Задача генерации объектов](theory/T38.md)
* [Вариационный автокодировщик](theory/T39.md)
* [GANs](theory/T40.md)
* [Диффузная модель](theory/T41.md)
